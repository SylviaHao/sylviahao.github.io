[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "About me!"
  },
  {
    "objectID": "space.html",
    "href": "space.html",
    "title": "space",
    "section": "",
    "text": "Today is January 9th, we’re working with the ’Objects Launched into Space” data from April 23, 2024 from Tidy Tuesday.\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n###1. import the data\n\n\nCode\n# Option 1: tidytuesdayR package \n## install.packages(\"tidytuesdayR\")\ntuesdata &lt;- tidytuesdayR::tt_load('2024-04-23')\n\n\n---- Compiling #TidyTuesday Information for 2024-04-23 ----\n--- There is 1 file available ---\n\n\n── Downloading files ───────────────────────────────────────────────────────────\n\n  1 of 1: \"outer_space_objects.csv\"\n\n\nCode\nouter_space_objects &lt;- tuesdata$outer_space_objects\n\n\n###2. tidy - The data appears already tidy at a glance, but let’s double check.\n\n\nCode\nskimr::skim(outer_space_objects)\n\n\n\nData summary\n\n\nName\nouter_space_objects\n\n\nNumber of rows\n1175\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEntity\n0\n1.00\n4\n21\n0\n110\n0\n\n\nCode\n142\n0.88\n3\n8\n0\n97\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nYear\n0\n1\n2002.17\n16.78\n1957\n1991\n2006\n2017.0\n2023\n▁▂▃▅▇\n\n\nnum_objects\n0\n1\n29.44\n162.09\n1\n1\n2\n6.5\n2664\n▇▁▁▁▁\n\n\n\n\n\nCode\n#What's the relationship between entity and code? is there a 1-1 relationship?\n\n\n###3. Transform\n\n\nCode\n#outer_space_objects |&gt; filter(Year == min(Year))\n\n#It appears that the entity 'world' is an aggregated sum of all the objects released that year. It may be not useful for plotting or aggregating statistics, so we'll create our own table 'space' that doesn't the Entity of 'world' in it.\n\nspace &lt;- outer_space_objects |&gt; filter(Entity != 'World')\n\n#I also want to make the distinction bewteen countries and non-countries.\nspace$Country &lt;- dplyr::if_else(is.na(space$Code), true = 'Non-Country', false = 'Country')\n\n\n####The prompt for today are:\n\nWhen did each entity start launching objects into space?\n\nWe can get started with these prompts and then see what else we might be interested in. Maybe even some projections?\n###4. Visualize\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nCode\nggplot(space |&gt; group_by(Entity) |&gt; slice(which.min(Year)),\n       aes(x = Year, y = num_objects, group = Entity, label = Entity)) + \n  geom_jitter() + \n  geom_text() +\n  theme_bw()\n\n\n\n\n\n\nWhat years saw the biggest increase in space object launches?\n\n\n\nCode\nlibrary(ggplot2)\nggplot(space |&gt; group_by(Year) |&gt; summarize(total = sum(num_objects)),\n       aes(x = Year, y = total)) + \n  geom_jitter() + \n  theme_bw() +\n  labs(x = 'Year', y = 'Total Objects', title = 'Total Number of Objects Launched Per Year')\n\n\n\n\n\n\nWhat’s interesting about this is the question: `What entity is contributing to the sudden increase of the total number of objects launched per year?’. We can also attempt to numerically calculate the percentage change each year in the total number of objects, and also group it by entity!\n\n\n\nCode\n#As there are a lot of entities and countries, it may be good to create some distinction between countries/entities that launch a lot of things vs not alot.\n\ntotal_df &lt;- space |&gt; group_by(Entity) |&gt; summarize(total = sum(num_objects))\n\ntotal_df\n\n\n# A tibble: 109 × 2\n   Entity     total\n   &lt;chr&gt;      &lt;dbl&gt;\n 1 APSCO          1\n 2 Algeria        6\n 3 Angola         2\n 4 Arabsat       15\n 5 Argentina     22\n 6 Armenia        1\n 7 Australia     47\n 8 Austria        3\n 9 Azerbaijan     3\n10 Bangladesh     2\n# ℹ 99 more rows\n\n\nThere are {r} nrow(total_df[total_df$total == 1, ] out of {r} length(unique(total_df$Entity)) entities that have only launched one object ever. These are not terribly useful.\n\n\nCode\nggplot(total_df |&gt; filter(total &lt;= 500), aes(x = total)) + geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\n#If we plot the total number launched below 500, we can see perhaps an easier filter for what entities to include.\n\n#We'll limit it onlt to entities that have launched over a total of 100 objects\n\n\n#First let’s look at the same plot we already made but change the color?\n\n\nCode\nlibrary(ggplot2)\nspace_filtered &lt;- space |&gt; group_by(Entity) |&gt; mutate(total = sum(num_objects)) |&gt; filter(total &gt;= 100)\n\nggplot(space_filtered,\n       aes(x = Year, y = num_objects, fill = Entity)) + \n  geom_histogram(position = 'stack', stat = 'identity') + \n  theme_bw() +\n  labs(x = 'Year', y = 'Total Objects', title = 'Total Number of Objects Launched Per Year')\n\n\nWarning in geom_histogram(position = \"stack\", stat = \"identity\"): Ignoring\nunknown parameters: `binwidth`, `bins`, and `pad`\n\n\nWarning in vp$just: partial match of 'just' to 'justification'\n\n\n\n\n\n\n\nCode\n#Calculate percentage change per year for these 15 entities.\n#We can see that there's only a record listed for when something was launched, so for years where there was no launch the number remained the same. We'll have to create a dataframe that has all the years filled in.\nspace_full &lt;- expand.grid(seq(min(space_filtered$Year), max(space_filtered$Year), by = 1),\n            unique(space_filtered$Entity))\nnames(space_full) &lt;- c('Year', 'Entity')\nspace_full['Number'] &lt;- 0\nspace_full &lt;- left_join(space_full, space_filtered |&gt; select(Year, Entity, num_objects), by = c(\"Year\", 'Entity'))\nspace_full$num_objects[is.na(space_full$num_objects)] &lt;- 0\n\ndelta_df &lt;- space_full |&gt; group_by(Entity, Year) |&gt; mutate(running_total = cumsum(num_objects)) |&gt; mutate(delta = (running_total-lag(running_total))/running_total)\n\n#percentage change from year to year\n\n\n\n\nCode\nlibrary(plotly)\n\n\nWarning: package 'plotly' was built under R version 4.2.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nlibrary(ggplot2)\n\naccumulate_by &lt;- function(dat, var) {\n  var &lt;- lazyeval::f_eval(var, dat)\n  lvls &lt;- plotly:::getLevels(var)\n  dats &lt;- lapply(seq_along(lvls), function(x) {\n    cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])\n  })\n  dplyr::bind_rows(dats)\n}\n\nfig_df &lt;- delta_df |&gt; accumulate_by(~Year)\n# fig_df &lt;- fig_df |&gt; group_by(frame) |&gt; mutate(id = row_number())\n# delta_df$id &lt;- seq.int(nrow(delta_df))\n\n#delta_df\n\n#we basically need to make 'intermediate' plots for this, and each intermediate plot would be indicated as frame X out of frame Y.\n#The first plot would only have the first year, then the second plot the data from years 1 and 2, so on.\n\n#There are 67 years, ranging from 1957 to 2023\n\n\ng1 &lt;- ggplot(fig_df,\n       aes(x = Year, y = running_total, frame = frame, color = Entity)) + \n  geom_line(stat = 'identity') \n  #geom_point() +\n  # geom_text(data = \n  #              space_filtered |&gt; group_by(Entity) |&gt; mutate(Total = cumsum(num_objects)) |&gt; filter(Year == last(Year)),\n  #      aes(label = Entity),\n  #      show.legend = FALSE) +\n  # theme_bw() +\n  # labs(x = 'Year',\n  #      y = 'Total',\n  #      title = 'Total Objects Launched from 1957 - 2023')\n\n\nfig &lt;- ggplotly(g1) \n\nfig %&gt;% animation_opts(\n  frame = 300, \n  transition = , \n  redraw = FALSE\n)"
  },
  {
    "objectID": "parfumo.html",
    "href": "parfumo.html",
    "title": "parfumo",
    "section": "",
    "text": "Today is Thursday, December 12th and I’m working on this weeks’ tidy tuesday dataset sourced from Parfumo.\nMy goals for today are to continue to practise using dplyr::across and dplyr::map functions, and to create some visualizations using packages I’ve not used before!\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\n\n\n\n\nCode\n# Option 1: tidytuesdayR package \n## install.packages(\"tidytuesdayR\")\n# tuesdata &lt;- tidytuesdayR::tt_load('2024-12-10')\n# ## OR\ntuesdata &lt;- tidytuesdayR::tt_load(2024, week = 50)\n\nparfumo_data_clean &lt;- tuesdata$parfumo_data_clean\n\n# Option 2: Read directly from GitHub\n# \n# parfumo_data_clean &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-12-10/parfumo_data_clean.csv')\n\n\n\n\nData exploration\n\n\nCode\nskimr::skim(parfumo_data_clean)\n\n\n\nData summary\n\n\nName\nparfumo_data_clean\n\n\nNumber of rows\n59325\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nNumber\n57905\n0.02\n1\n5\n0\n362\n0\n\n\nName\n1\n1.00\n1\n120\n0\n55119\n0\n\n\nBrand\n1\n1.00\n2\n52\n0\n1451\n0\n\n\nConcentration\n46842\n0.21\n5\n40\n0\n412\n0\n\n\nMain_Accords\n27100\n0.54\n5\n48\n0\n19159\n0\n\n\nTop_Notes\n28186\n0.52\n3\n281\n0\n21743\n0\n\n\nMiddle_Notes\n28176\n0.53\n3\n407\n0\n22050\n0\n\n\nBase_Notes\n28171\n0.53\n3\n337\n0\n18023\n0\n\n\nPerfumers\n38781\n0.35\n4\n111\n0\n2448\n0\n\n\nURL\n0\n1.00\n3\n146\n0\n59281\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nRelease_Year\n20316\n0.66\n2006.26\n22.88\n1709\n2005.0\n2013.0\n2018.0\n2024\n▁▁▁▁▇\n\n\nRating_Value\n29279\n0.51\n7.35\n0.93\n0\n6.9\n7.4\n7.9\n10\n▁▁▁▇▂\n\n\nRating_Count\n29279\n0.51\n60.65\n118.19\n2\n6.0\n19.0\n62.0\n2732\n▇▁▁▁▁\n\n\n\n\n\nImmediately we can see that quite a large number of perfumes have missing information, such as concentration, the notes, and perfumers. We can look to see if the missingness is correlated across variables. We can plot this using a correlation matrix.\n\n\nCode\nparfumo_missing &lt;- parfumo_data_clean %&gt;%\n  mutate(across(Concentration:Perfumers, ~ !is.na(.), .names = \"{.col}_missing\"))\n\nmissing_cor_df &lt;- cor(parfumo_missing |&gt; select(contains('Missing')))\nrange(missing_cor_df)\n\n\n[1] 0.01594804 1.00000000\n\n\nCorrelation ranges from 0.0159 to 1, no negative correlations.\n\n\nCode\n#install.packages('ggcorrplot')\nlibrary(ggcorrplot)\nggcorrplot::ggcorrplot(missing_cor_df, type = 'lower', colors = c('white', 'pink', 'red'))\n\n\n\n\n\nThe good news is that it looks like if any of the notes are missing, the the other notes are missing as well. The rating count and rating value are also highly correlated, which is unsurprising as well.\n\n\nCode\n#Since there are a lot of text for the main accords, we'll have to make it long format when we split up the main accords.\n#if we're only looking at accords, we can make it into a long dataframe\naccords_vec &lt;- parfumo_data_clean |&gt; filter(!is.na(Rating_Value)) |&gt; \n  mutate(accords = strsplit(as.character(Main_Accords), split = \", \")) |&gt; \n  tidyr::unnest(accords)\n\n\nThe prompts today are:\n1. What factors most influence the rating of a perfume?\n2. Are there distinct scent families that dominate the market, and how are they perceived by users?\n3. Has the popularity of certain fragrance notes evolved over time?\n\n\nCode\n#If I want to have a plot of the range of values and accords\nggplot(data = accords_vec, aes(x = Rating_Value, y = accords, fill = accords)) + geom_boxplot() + theme_bw() + labs(x = 'Rating Value', y = 'Accords', title = 'Distribution of Ratings Across Accords')"
  },
  {
    "objectID": "border_crossing.html",
    "href": "border_crossing.html",
    "title": "Border Census",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\n\nCode\ncbp_resp &lt;- bind_rows(\n  read_csv(\"https://www.cbp.gov/sites/default/files/assets/documents/2023-Nov/nationwide-encounters-fy20-fy23-aor.csv\"),\n  read_csv(\"https://www.cbp.gov/sites/default/files/2024-10/nationwide-encounters-fy21-fy24-aor.csv\")\n) |&gt;\n  janitor::clean_names() |&gt;\n  unique()\n\ncbp_state &lt;- bind_rows(\n  read_csv(\"https://www.cbp.gov/sites/default/files/assets/documents/2023-Nov/nationwide-encounters-fy20-fy23-state.csv\"),\n  read_csv(\"https://www.cbp.gov/sites/default/files/2024-10/nationwide-encounters-fy21-fy24-state.csv\")\n) |&gt;\n  janitor::clean_names() |&gt;\n  unique()\n\n\n\n\nCode\nskimr::skim(cbp_resp)\n\n\n\nData summary\n\n\nName\ncbp_resp\n\n\nNumber of rows\n68815\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmonth_grouping\n0\n1\n4\n4\n0\n1\n0\n\n\nmonth_abbv\n0\n1\n3\n3\n0\n12\n0\n\n\ncomponent\n0\n1\n18\n26\n0\n2\n0\n\n\nland_border_region\n0\n1\n5\n21\n0\n3\n0\n\n\narea_of_responsibility\n0\n1\n11\n26\n0\n41\n0\n\n\naor_abbv\n0\n1\n3\n13\n0\n41\n0\n\n\ndemographic\n0\n1\n4\n18\n0\n4\n0\n\n\ncitizenship\n0\n1\n4\n26\n0\n22\n0\n\n\ntitle_of_authority\n0\n1\n7\n8\n0\n2\n0\n\n\nencounter_type\n0\n1\n10\n13\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfiscal_year\n0\n1\n2022.20\n1.35\n2020\n2021\n2022\n2023\n2024\n▅▆▇▇▇\n\n\nencounter_count\n0\n1\n166.71\n727.46\n0\n2\n9\n57\n25457\n▇▁▁▁▁\n\n\n\n\n\nCode\nskimr::skim(cbp_state)\n\n\n\nData summary\n\n\nName\ncbp_state\n\n\nNumber of rows\n54939\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmonth_grouping\n0\n1\n4\n4\n0\n1\n0\n\n\nmonth_abbv\n0\n1\n3\n3\n0\n12\n0\n\n\nland_border_region\n0\n1\n5\n21\n0\n3\n0\n\n\nstate\n0\n1\n2\n2\n0\n48\n0\n\n\ndemographic\n0\n1\n4\n18\n0\n4\n0\n\n\ncitizenship\n0\n1\n4\n26\n0\n22\n0\n\n\ntitle_of_authority\n0\n1\n7\n8\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfiscal_year\n0\n1\n2022.23\n1.36\n2020\n2021\n2022\n2023\n2024\n▅▆▇▇▇\n\n\nencounter_count\n0\n1\n208.82\n1090.00\n0\n2\n9\n46\n36802\n▇▁▁▁▁\n\n\n\n\n\nLet’s start with just looking at the number of border crossings across time by land border region\n\n\nCode\nlibrary(ggplot2)\n\nggplot(cbp_state, aes(x = month_abbv, y = encounter_count, fill = land_border_region)) +\n  geom_histogram(stat = 'identity') + \n  theme_bw() + \n  facet_grid(.~ fiscal_year) + \n  labs(x = 'Time', y = 'Count', title = 'Number of Border Crossings Across FY2020 - FY2024 by Land Border Region') + \n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-4))\n\n\n\n\n\nIf we wanted to plot the number of encounters on a map by state, how would we do that?\n\n\nCode\n# library(tidycensus)\n# \n# #getting tidycensus data\n# geography_df &lt;- get_acs(\n#   variables = \"B19013_001\",\n#   geography = \"state\",\n#   geometry = TRUE,\n#   year = 2020\n# )\n# \n# geography_df$state_abbr &lt;- state.abb[match(geography_df$NAME, state.name)]\n# \n# #add the geography information to the cbp_state data\n# \n# cbp_state$geometry &lt;- geography_df$geometry[match(cbp_state$state, geography_df$state_abbr)]\n# \n# #Now we can generate the plot\n# \n# cbp_grouped &lt;-  cbp_state |&gt; group_by(fiscal_year, geometry) |&gt; summarize(total = sum(encounter_count)) |&gt; sf::st_sf()\n# \n# ggplot(cbp_grouped, aes(fill = total)) +\n#   geom_sf(color = NA) +\n#   facet_wrap(~fiscal_year)\n\n\nPretty ugly but at least we got somewhere as a starting point.\nNow maybe let’s work on the prompts…\nPrompts from Tidy Tuesday:\n1. How has the implementation (and potential end) of Title 42 affected migration and enforcement trends compared to Title 8 actions?\nIf we look at things from the state level…\n\n\nCode\nggplot(cbp_state |&gt; mutate(Date = lubridate::ym(paste(fiscal_year, month_abbv))) |&gt; \n         group_by(Date, title_of_authority, land_border_region) |&gt; \n         summarize(total = sum(encounter_count)),  \n         aes(x = Date, y = total, color = title_of_authority, shape = land_border_region)) +\n  geom_point(stat = 'identity') + \n  geom_line() + \n  theme_bw() + \n  facet_wrap(~ land_border_region) + \n  labs(x = 'Time', y = 'Count', title = 'Number of Border Crossings Across FY2020 - FY2024 by Land Border Region') + \n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-4))\n\n\n\n\n\nit looks like there are some yo-yo and reactionary trends, it could be related to court decisions. Almost entirely restricted to the Southwest Land Border.\nIf we look at people with the same citizenship trying to cross at the north vs south borders, what would that look like?\n\n\nCode\nggplot(cbp_state |&gt; \n         filter(citizenship %in% c(\"INDIA\", \"CHINA, PEOPLES REPUBLIC OF\", \"OTHER\")) |&gt; \n         mutate(Date = lubridate::ym(paste(fiscal_year, month_abbv))) |&gt; \n         group_by(Date, title_of_authority, land_border_region, citizenship) |&gt; \n         summarize(total = sum(encounter_count)),  \n         aes(x = Date, y = total, color = title_of_authority, shape = land_border_region)) +\n  geom_point(stat = 'identity') + \n  geom_line() + \n  theme_bw() + \n  facet_wrap(citizenship ~ land_border_region) + \n  labs(x = 'Time', y = 'Count', title = 'Number of Border Crossings Across FY2020 - FY2024 by Land Border Region') + \n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-4))\n\n\n\n\n\nCode\nggplot(cbp_state |&gt; \n         filter(citizenship %in% c(\"MEXICO\", \"VENEZUELA\", \"GUATEMALA\", \"HAITI\")) |&gt; \n         mutate(Date = lubridate::ym(paste(fiscal_year, month_abbv))) |&gt; \n         group_by(Date, title_of_authority, land_border_region, citizenship) |&gt; \n         summarize(total = sum(encounter_count)),  \n         aes(x = Date, y = total, color = title_of_authority, shape = land_border_region)) +\n  geom_point(stat = 'identity') + \n  geom_line() + \n  theme_bw() + \n  facet_wrap(citizenship ~ land_border_region) + \n  labs(x = 'Time', y = 'Count', title = 'Number of Border Crossings Across FY2020 - FY2024 by Land Border Region') + \n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-4))\n\n\n\n\n\nWhile we see Mexico with overwhelmingly the number of denied border crossings, the pattern exhibited for Mexico is unlike the pattern for any other country, at any other land border.\n\n\nCode\nggplot(cbp_state |&gt; \n         filter(citizenship %in% c(\"MEXICO\") & land_border_region == 'Southwest Land Border') |&gt; \n         mutate(Date = lubridate::ym(paste(fiscal_year, month_abbv))) |&gt; \n         group_by(Date, title_of_authority, demographic) |&gt; \n         summarize(total = sum(encounter_count)),  \n         aes(x = Date, y = total, color = title_of_authority)) +\n  geom_point(stat = 'identity') + \n  geom_line() + \n  theme_bw() + \n  facet_wrap(~demographic) + \n  labs(x = 'Time', y = 'Count', title = 'Number of Border Crossings Across FY2020 - FY2024 by Land Border Region') + \n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-4))"
  },
  {
    "objectID": "olympics.html",
    "href": "olympics.html",
    "title": "olympics",
    "section": "",
    "text": "#Today we’re using the Olympics data sourced from Tidy Tuesday.\nCode\ntuesdata &lt;- tidytuesdayR::tt_load('2024-08-06')\n\nolympics &lt;- tuesdata$olympics\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(plotly)\nLet’s take a quick look at the dataset.\nCode\nskimr::skim(olympics)\n\n\n\nData summary\n\n\nName\nolympics\n\n\nNumber of rows\n271116\n\n\nNumber of columns\n15\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nname\n0\n1.00\n2\n108\n0\n134731\n0\n\n\nsex\n0\n1.00\n1\n1\n0\n2\n0\n\n\nteam\n0\n1.00\n2\n47\n0\n1184\n0\n\n\nnoc\n0\n1.00\n3\n3\n0\n230\n0\n\n\ngames\n0\n1.00\n11\n11\n0\n51\n0\n\n\nseason\n0\n1.00\n6\n6\n0\n2\n0\n\n\ncity\n0\n1.00\n4\n22\n0\n42\n0\n\n\nsport\n0\n1.00\n4\n25\n0\n66\n0\n\n\nevent\n0\n1.00\n15\n85\n0\n765\n0\n\n\nmedal\n231333\n0.15\n4\n6\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1.00\n68248.95\n39022.29\n1\n34643\n68205\n102097.2\n135571\n▇▇▇▇▇\n\n\nage\n9474\n0.97\n25.56\n6.39\n10\n21\n24\n28.0\n97\n▇▃▁▁▁\n\n\nheight\n60171\n0.78\n175.34\n10.52\n127\n168\n175\n183.0\n226\n▁▂▇▂▁\n\n\nweight\n62875\n0.77\n70.70\n14.35\n25\n60\n70\n79.0\n214\n▃▇▁▁▁\n\n\nyear\n0\n1.00\n1978.38\n29.88\n1896\n1960\n1988\n2002.0\n2016\n▁▂▃▆▇\nIt looks like the number of medals has a fair number of missingness. If it’s missing does that mean that someone didn’t get the medal?\n####Data exploration: How’s the missingness for biometrics?\nCode\nolympics$age_na &lt;- as.numeric(is.na(olympics$age))\nolympics$height_na &lt;- as.numeric(is.na(olympics$height))\nolympics$weight_na &lt;- as.numeric(is.na(olympics$weight))\n\n#Is missingness associated with year?\nolympics_na_df &lt;- olympics |&gt; \n         group_by(year, sport) |&gt; \n         summarize(height_na_prop = sum(height_na)/n(),\n                   weight_na_prop = sum(weight_na)/n(),\n                   age_na_prop = sum(age_na)/n()) |&gt; \n  tidyr::pivot_longer(cols = height_na_prop:age_na_prop,\n                      names_to = 'biometric',\n                      values_to = 'prop')\n\ng1_missingness_overall &lt;- ggplot(olympics_na_df, aes(x = year, y = prop, color = sport, fill = sport)) + \n  geom_jitter() +\n  facet_grid(. ~ (biometric))+\n  labs(x = 'Year',\n       y = 'Proportion',\n       title = 'Missingness by Year, Sport, and Biometric') +\n  theme_bw()+\n  theme(legend.position = \"none\")\n\nggplotly(g1_missingness_overall)\nIt appears that the rate of missingness drastically goes down after ~1960. Okay, what if we just looked at swimming?\nCode\nggplot(olympics_na_df |&gt; filter(sport == 'Swimming'),\n  aes(x = year, y = prop, color = sport)) +\n    geom_point() + facet_grid(.~ biometric) +\n  theme_bw()+\n  labs(x = 'Year',\n       y = 'Proportion',\n       title = 'Biometric Missingness Proportion by Year (Swimming Only)')\nAge, height, and weight all have a fair bit of missingness as well. Conclusion: To make things easier, let’s just focus on a single sport (swimming) for now."
  },
  {
    "objectID": "olympics.html#goals-for-today",
    "href": "olympics.html#goals-for-today",
    "title": "olympics",
    "section": "Goals for today:",
    "text": "Goals for today:\n\nPlot an animated plot of how age, height, and weight changes across years for 100 metres freestyle swimming (practise previously learned animated plot).\nPredictive modelling for who will win the gold for future years? The total number of medals for future years? For this I’ll want to use sports with the longest complete lookback period. Not sure that participant biometrics matters?\n\n\nGoal 1 - Animation Plot\nLet’s see what the trends are across the 3 biometrics (age, height, weight) for 100 metres freestyle swimming across time for men and women.\n\n\nCode\nswim_100_men_df &lt;- olympics |&gt; filter(sport == 'Swimming' & year &gt;= 1960) |&gt; filter(event == 'Swimming Men\\'s 100 metres Freestyle') |&gt; select(age, height, weight, year, medal) |&gt; mutate(medalist = dplyr::if_else(is.na(medal), true = '0', false = '1')) |&gt; mutate(Sex = 'Men')\n\n\nswim_100_women_df &lt;- olympics |&gt; filter(sport == 'Swimming' & year &gt;= 1960) |&gt; filter(event == 'Swimming Women\\'s 100 metres Freestyle') |&gt; select(age, height, weight, year, medal) |&gt; mutate(medalist = dplyr::if_else(is.na(medal), true = '0', false = '1')) |&gt; mutate(Sex = 'women')\n\nswim_100_df &lt;- rbind(swim_100_men_df, swim_100_women_df)\n\nswim_100_df$medalist &lt;- factor(swim_100_df$medalist, levels = c('1', '0'), labels = c('Medalist', 'Non-Medalist'))\n\n#we can plot 'univariate' plots for now\nggplot(swim_100_df, aes(x = year, y = age, color = as.factor(medalist))) + \n  geom_jitter() + \n  facet_grid(.~ Sex) +\n  labs(x = 'Year',\n       y = 'Age',\n       title = 'Changes in Age of Medalist vs Non-Medalist for Swimming From 1960 to 2016') +\n  theme_bw()\n\n\n\n\n\nCode\nggplot(swim_100_df, aes(x = year, y = height, color = as.factor(medalist))) + \n  geom_jitter() + \n  facet_grid(.~ Sex) +\n  labs(x = 'Year',\n       y = 'Height',\n       title = 'Changes in Height of Medalist vs Non-Medalist for Swimming From 1960 to 2016') +\n  theme_bw()\n\n\n\n\n\nCode\nggplot(swim_100_df, aes(x = year, y = weight, color = as.factor(medalist))) + \n  geom_jitter() + \n  facet_grid(.~Sex) +\n  labs(x = 'Year',\n       y = 'Weight',\n       title = 'Changes in Weight of Medalist vs Non-Medalist for Swimming From 1960 to 2016') +\n  theme_bw()\n\n\n\n\n\nIt appears that age of winners is middle of the road, but height and weight seems to be trending higher.\n\n\nCode\n#only necessary if you want the graph to keep on growing, but not necessary for newly generated visuals\n# accumulate_by &lt;- function(dat, var) {\n#   var &lt;- lazyeval::f_eval(var, dat)\n#   lvls &lt;- plotly:::getLevels(var)\n#   dats &lt;- lapply(seq_along(lvls), function(x) {\n#     cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])\n#   })\n#   dplyr::bind_rows(dats)\n# }\n\n#fig_df &lt;- swim_100_df |&gt; filter(!is.na(height) & !is.na(weight)) |&gt; accumulate_by(~year)\nfig_df &lt;- swim_100_df |&gt; filter(!is.na(height) & !is.na(weight))\n\ng1 &lt;- ggplot(fig_df |&gt; arrange(desc(medalist)),\n       aes(x = height, y = weight, frame = year, color = medalist)) + \n  geom_jitter() +\n  #stat_ellipse() +\n  scale_color_manual(\n    values = c('Non-Medalist' = 'grey70',\n               'Medalist' = 'orange')\n  ) +\n  theme_bw()\n  #geom_point() +\n  # geom_text(data = \n  #              space_filtered |&gt; group_by(Entity) |&gt; mutate(Total = cumsum(num_objects)) |&gt; filter(Year == last(Year)),\n  #      aes(label = Entity),\n  #      show.legend = FALSE) +\n  # theme_bw() +\n  # labs(x = 'Year',\n  #      y = 'Total',\n  #      title = 'Total Objects Launched from 1957 - 2023')\n\n\nfig &lt;- ggplotly(g1)\n\nfig\n\n\n\n\n\n\nCode\n# fig %&gt;% animation_opts(\n# +     frame = 300, \n# +     transition = , \n# +     redraw = FALSE)\n\n\n\nRoadblock\nWe’re running into a situation where the gold medalists’ values appears to be obscured sometimes by the non-winners. Is there a way to always make them appear on top? It appears there used to be an ‘order’ aesthetic in ggplot but it’s since been deprecated. Now you can just arrange your data to achieve the same outcome.\nI want to: 1. make the gold medalist points bigger\n\ncreate cloud/ellipses around distributions\nlower the alpha of the individual points?\n\n\n\nCode\ng2 &lt;- ggplot(fig_df |&gt; arrange(desc(medalist)) |&gt; distinct(),\n       aes(x = height, y = weight, frame = year, color = medalist, fill = medalist, alpha = medalist, size = medalist, label = year)) + \n  # annotate(geom=\"text\", x=3, y=30,\n  #             color=\"red\") +\n  geom_jitter() +\n  geom_density_2d(\n  data = fig_df |&gt; filter(medalist == 'Non-Medalist'),\n  aes(x = height, y = weight, frame = year)) +\n  scale_color_manual(\n    values = c('Non-Medalist' = 'grey70',\n               'Medalist' = 'orange')\n  ) +\n  scale_fill_manual(\n    values = c('Non-Medalist' = 'grey70',\n               'Medalist' = 'orange')\n  ) +\n  theme_bw() +\n  scale_alpha_discrete(range = c(1, 0.4)) +\n  scale_size_manual(\n    values = c('Non-Medalist' = 1,\n               'Medalist' = 3)) +\n  labs(x = 'Height (cm)',\n       y = 'Weight (kg)',\n       title = 'Changes in Height and Weight from 1960 to 2016 in 100 Metre Freestyle Swimming') +\n  facet_grid(. ~ Sex)\n\nfig_better &lt;- ggplotly(g2)\n\nfig_better\n\n\n\n\n\n\n#Summary I was able to create an animated visualization (goal 1 completed). The contours is created using 2D kernal density estimation. I didn’t end up having time for modelling.\n#Future things to work on: 1. Play around more with animations. 2. Explore ellipses or other ways to show changes in distribution of data across time? 3. Predictive modelling."
  }
]